{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac654c2",
   "metadata": {},
   "source": [
    "# NLP Starter Notebook\n",
    "\n",
    "Explore tokenization, datasets, and a quick text classification fine-tune with ðŸ¤— Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2511ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (if running in a fresh environment)\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load a small sample from AG News\n",
    "ds = load_dataset(\"ag_news\")\n",
    "df = pd.DataFrame(ds[\"train\"][:1000])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution plot\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title('Label Distribution (sample)')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "example = df['text'][0]\n",
    "tokens = tokenizer.tokenize(example)[:50]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053898a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick train with Trainer (1 epoch to smoke-test)\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "tokenized = ds.map(lambda b: tokenizer(b['text'], truncation=True), batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "args = TrainingArguments(\"checkpoints-notebook\", num_train_epochs=1, per_device_train_batch_size=16, per_device_eval_batch_size=16, evaluation_strategy=\"epoch\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=preds, references=labels)['accuracy']}\n",
    "\n",
    "trainer = Trainer(model, args, train_dataset=tokenized['train'].select(range(2000)),\n",
    "                  eval_dataset=tokenized['test'].select(range(1000)),\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=DataCollatorWithPadding(tokenizer))\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824b0d8",
   "metadata": {},
   "source": [
    "## Optional: spaCy quick demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "# [(t.text, t.pos_, t.dep_) for t in doc]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}