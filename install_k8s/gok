#!/bin/bash

: ${WORKING_DIR:=$MOUNT_PATH/kubernetes/install_k8s}
source "$WORKING_DIR"/config

release=$2
CMD=$1
#dns, http, selfsigned
CERTMANAGER_CHALANGE_TYPE=selfsigned
#staging, prod
LETS_ENCRYPT_ENV=staging

echoSuccess(){
  echo -e "\e[32m$1\e[0m"
}

echoFailed(){
  echo -e "\e[31m$1\e[0m"
}

echoWarning(){
  echo -e "\e[32m$1\e[0m"
}

createApp1() {
  cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app1
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app1
  template:
    metadata:
      labels:
        app: app1
    spec:
      containers:
      - name: app1
        image: dockersamples/static-site
        env:
        - name: AUTHOR
          value: app1
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: appsvc1
  namespace: default
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: app1
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: "nginx"
  name: app-ingress
  namespace: default
spec:
  rules:
  - host: master.cloud.com
    http:
      paths:
      - backend:
          service:
            name: appsvc1
            port:
              number: 80
        path: /app1
        pathType: Prefix
EOF
}

getpod() {
  pod=$(kubectl get po -l app.kubernetes.io/name="$release" 2>/dev/null | awk "/${release}/" | awk '{print $1}' | head -n 1)
  echo "$pod"
}

updateSys() {
  apt-get update
}

setupDockerRegistry(){
  [[ "TRACE" ]] && set -x

  EXPORTDIR=$MOUNT_PATH

  if [ $(hostname) == 'master.cloud.com' ]; then
      mkdir -p "$EXPORTDIR"/certs
      mkdir -p /mnt/registry
      rm -rf /mnt/registry/config.yml
      wget https://github.com/sumitmaji/kubernetes/raw/master/install_k8s/registry/config.yml -P /mnt/registry/
      pushd "$EXPORTDIR"
      USERNAME=master.cloud.com
      FILENAME=registry
      CERTIFICATE_KEY_NAME=$USERNAME
      rm /etc/docker/certs.d/master.cloud.com:5000/${CERTIFICATE_KEY_NAME}.crt
      rm /root/certs/${CERTIFICATE_KEY_NAME}.crt
      rm /root/certs/${CERTIFICATE_KEY_NAME}.key
      if [ -f /etc/docker/certs.d/master.cloud.com:5000/${CERTIFICATE_KEY_NAME}.crt ]
      then
        echo "The file is present, not creating it!!!!!"
      else
        createCertificate -i 11.0.0.1 -h master.cloud.com -t server -f registry
      fi

      docker stop registry
      docker rm registry

      docker run -d \
        --restart=always \
        --name registry \
        -v $EXPORTDIR/certs:/root/certs \
        -e REGISTRY_HTTP_ADDR=0.0.0.0:5000 \
        -e REGISTRY_HTTP_TLS_CERTIFICATE=/root/certs/${CERTIFICATE_KEY_NAME}.crt \
        -e REGISTRY_HTTP_TLS_KEY=/root/certs/${CERTIFICATE_KEY_NAME}.key \
        -v /mnt/registry:/var/lib/registry \
        -v /mnt/registry/config.yml:/etc/docker/registry/config.yml \
        -p 5000:5000 \
        registry:latest

      mkdir -p /etc/docker/certs.d/master.cloud.com:5000

      cp "$EXPORTDIR"/certs/${CERTIFICATE_KEY_NAME}.crt /etc/docker/certs.d/master.cloud.com:5000/${CERTIFICATE_KEY_NAME}.crt

      popd
  else
      mkdir -p /etc/docker/certs.d/master.cloud.com:5000
      cp "$EXPORTDIR"/certs/${USERNAME}.crt /etc/docker/certs.d/master.cloud.com:5000/${USERNAME}.crt
  fi
}

installDeps() {
  #Install network tools
  apt-get install net-tools
  apt-get install jq -y

  #Installing python
  apt-get install python3 -y
  apt-get install python3-pip -y

}

ingressUnInst() {
  output=$(kubectl get po -n ingress-nginx -l app.kubernetes.io/component=controller -o json | jq '.items | length')
  if [ "$output" == "1" ]; then
    helm uninstall ingress-nginx
    kubectl delete ns ingress-nginx
  fi
}

ingressInst() {
  helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
  helm repo update
  helm install \
    ingress-nginx ingress-nginx/ingress-nginx \
    --namespace ingress-nginx \
    --create-namespace \
    --set controller.service.nodePorts.http=80 \
    --set controller.service.nodePorts.https=443 \
    --set controller.service.type=NodePort \
    --set defaultBackend.enabled=true
  #    -f charts/values.yaml

  output=$(kubectl get po -n ingress-nginx -l app.kubernetes.io/component=controller -ojsonpath='{.items[0].status.containerStatuses[0].ready}')
  while [ "$output" != "true" ]; do
    echo "Ingress controller service is not up, will check again after 5seconds"
    sleep 5
    output=$(kubectl get po -n ingress-nginx -l app.kubernetes.io/component=controller -ojsonpath='{.items[0].status.containerStatuses[0].ready}')
  done
}

dockrInst() {

  echo "Installing docker"
  apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    software-properties-common
  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
  sudo install -m 0755 -d /etc/apt/keyrings
  sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
  sudo chmod a+r /etc/apt/keyrings/docker.asc

  # Add the repository to Apt sources:
  echo \
    "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
    $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
    sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
  sudo apt-get update

  apt-get update && apt-get install -y \
    docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

  # Create required directories
  sudo mkdir -p /etc/systemd/system/docker.service.d

  # Create daemon json config file
  sudo tee /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

  # Start and enable Services
  sudo systemctl daemon-reload
  sudo systemctl restart docker
  sudo systemctl enable docker

  # Start and enable containerd services
  sudo systemctl enable containerd
  sudo systemctl start containerd
  sudo rm /etc/containerd/config.toml
  sudo systemctl restart containerd
}

customDns() {
  #Adding custom dns server
  cat <<EOF | kubectl apply -f -
apiVersion: v1
data:
  Corefile: |
    .:53 {
        errors
        health {
           lameduck 5s
        }
        ready
        kubernetes cloud.uat in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153
        forward . /etc/resolv.conf {
           max_concurrent 1000
        }
        cache 30
        loop
        reload
        loadbalance
    }
    cloud.com:53 {
        errors
        cache 30
        forward . 11.0.0.1
    }
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
EOF

  kubectl delete pod --namespace kube-system -l k8s-app=kube-dns
}

taintNode() {
  echo "Going to taint node for scheduling in master"
  : ${IP:=$(ifconfig eth2 2>/dev/null | awk '/inet / {print $2}' | sed 's/addr://')}
  if [ -z "$IP" ]; then
    : ${IP:=$(ifconfig enp0s3 2>/dev/null | awk '/inet / {print $2}' | sed 's/addr://')}
  fi
  JSONPATH="{.items[?(@.status.addresses[0].address == \"${IP}\")].metadata.name}"
  NODE_NAME="$(kubectl get nodes -o jsonpath="$JSONPATH")"
  kubectl taint node "${NODE_NAME}" node-role.kubernetes.io/control-plane:NoSchedule-

}

k8sInst() {
  # Enable kernel modules
  sudo modprobe overlay
  sudo modprobe br_netfilter

  # Add some settings to sysctl
  sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

  # Reload sysctl
  sudo sysctl --system
  sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF
  sysctl --system
  mkdir -p /etc/containerd
  containerd config default>/etc/containerd/config.toml

  #https://github.com/containerd/containerd/blob/main/docs/cri/config.md#cgroup-driver
  sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
  systemctl restart containerd
  systemctl enable containerd


  echo "Installing Kubernetes"
  apt-get update && apt-get install -y apt-transport-https
  sudo apt-get update
  # apt-transport-https may be a dummy package; if so, you can skip that package
  sudo apt-get install -y apt-transport-https ca-certificates curl

  # If the folder `/etc/apt/keyrings` does not exist, it should be created before the curl command, read the note below.
  # sudo mkdir -p -m 755 /etc/apt/keyrings
  curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
  sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg # allow unprivileged APT programs to read this keyring
  # This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list
  echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
  sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list   # helps tools such as command-not-found to work correctly

  sudo apt-get update
  sudo apt-get install -y kubectl kubeadm kubelet

  kubeadm version
  kubeadm config images pull

  sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
  sudo swapoff -a

  sudo systemctl enable kubelet

  envsubst <"$WORKING_DIR"/cluster-config-master.yaml >"$WORKING_DIR"/config.yaml
  kubeadm init --config="$WORKING_DIR"/config.yaml
  export KUBECONFIG=/etc/kubernetes/admin.conf

  mkdir -p "$HOME"/.kube
  sudo cp -i /etc/kubernetes/admin.conf "$HOME"/.kube/config

  # shellcheck disable=SC2181
  if [ $? -ne 0 ]; then
    echo "Kubectl command execution failed, please check!!!!!"
    exit 1
  fi

}

calicoInst(){
  kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml

  if [ $? -ne 0 ]; then
    echo "Calico installation failed, please check!!!!!"
    exit 1
  fi
}

helmInst() {
  #Installing helm
  curl https://baltocdn.com/helm/signing.asc | apt-key add - &&
    apt-get install apt-transport-https --yes &&
    echo "deb https://baltocdn.com/helm/stable/debian/ all main" | tee /etc/apt/sources.list.d/helm-stable-debian.list &&
    apt-get update &&
    apt-get install helm &&
    helm version --short &&
    helm repo add stable https://charts.helm.sh/stable

}

certmanagerInst() {
  helm repo add jetstack https://charts.jetstack.io
  helm repo update
  kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.14.5/cert-manager.crds.yaml

  helm install \
    cert-manager jetstack/cert-manager \
    --namespace cert-manager \
    --create-namespace \
    --version v1.14.5
}

subDomain(){
  if [ -z $1 ]; then
    echo "kube"
  else
    echo "$1"
  fi
}

certificateRequestForNs() {
  NS=$1
  SUBDOMAIN=$(subDomain $2)
  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: ${SUBDOMAIN}-gokcloud-com-tls
  namespace: ${NS}
spec:
  secretName: ${SUBDOMAIN}-gokcloud-com
  issuerRef:
    name: $(getClusterIssuerName)
    kind: ClusterIssuer
  commonName: ${SUBDOMAIN}.gokcloud.com
  dnsNames:
    - ${SUBDOMAIN}.gokcloud.com
  issuerRef:
    name: $(getClusterIssuerName)
    kind: ClusterIssuer
EOF
  echo "Certificate request for NS $NS created, executing below command to know current status"
  echo "kubectl get Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges --all-namespaces"
  kubectl get Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges --all-namespaces
  kubectl --timeout=10s -n ${NS} wait --for=condition=Ready certificates.cert-manager.io ${SUBDOMAIN}-gokcloud-com-tls
}

getLetsEncryptUrl(){
  [[ getLetsEncEnv = 'prod' ]] && echo "https://acme-v02.api.letsencrypt.org/directory " || echo "https://acme-staging-v02.api.letsencrypt.org/directory"
}

getLetsEncEnv(){
  echo ${LETS_ENCRYPT_ENV}
}

getClusterIssuerName(){
  case "$CERTMANAGER_CHALANGE_TYPE" in
   'dns') echo "letsencrypt-$(getLetsEncEnv)" ;;
   'http') echo "letsencrypt-$(getLetsEncEnv)" ;;
   'selfsigned') echo "gokselfsign-ca-cluster-issuer" ;;
  esac
}

setupCertiIssuers() {

if [ $CERTMANAGER_CHALANGE_TYPE == 'dns' ]; then
  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: $(getClusterIssuerName)
spec:
  acme:
    email: majisumitkumar@gmail.com
    server: $(getLetsEncryptUrl)
    privateKeySecretRef:
      name: letsencrypt-$(getLetsEncEnv)
    solvers:
    - dns01:
        webhook:
          config:
            apiKeySecretRef:
              name: godaddy-api-key-secret
              key: api-key
            production: true
            ttl: 600
          groupName: acme.mycompany.com
          solverName: godaddy
      selector:
       dnsNames:
       - 'kube.gokcloud.co.in'
       - '*.gokcloud.co.in'
EOF
  godaddyWebhook
elif [ $CERTMANAGER_CHALANGE_TYPE == 'http' ]; then
    

  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: $(getClusterIssuerName)
spec:
  acme:
    email: majisumitkumar@gmail.com
    server: $(getLetsEncryptUrl)
    #preferredChain: "(STAGING) Pretend Pear X1"
    privateKeySecretRef:
      name: letsencrypt-$(getLetsEncEnv)
    solvers:
    - http01:
        ingress:
          ingressClassName: nginx
EOF

elif [ $CERTMANAGER_CHALANGE_TYPE == 'selfsigned' ]; then
  # https://medium.com/geekculture/a-simple-ca-setup-with-kubernetes-cert-manager-bc8ccbd9c2
  # https://gist.github.com/jakexks/c1de8238cbee247333f8c274dc0d6f0f
  # Create self signed cluster issuer:
  echo "Creating self-signed cluster-issuer..."
  until cat <<EOYAML | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-cluster-issuer
spec:
  selfSigned: {}
EOYAML
  do sleep 1; done
  kubectl --timeout=10s wait --for=condition=Ready clusterissuers.cert-manager.io selfsigned-cluster-issuer

  # Create CA certificate. If you want to use it as a ClusterIssuer the secret must be in the cert-manager namespace:
  echo "Creating self-signed certificate..."
  cat <<EOYAML | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: gokselfsign-ca
  namespace: cert-manager
spec:
  isCA: true
  commonName: gokselfsign-ca
  secretName: gokselfsign-ca
  subject:
    organizations:
      - GOK Inc.
    organizationalUnits:
      - Widgets
  privateKey:
    algorithm: ECDSA
    size: 256
  issuerRef:
    name: selfsigned-cluster-issuer
    kind: ClusterIssuer
    group: cert-manager.io
EOYAML
  kubectl --timeout=10s -n cert-manager wait --for=condition=Ready certificates.cert-manager.io gokselfsign-ca

  # Create clusterissuer
  echo "Creating CA cluster issuer..."
  cat <<EOYAML | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: $(getClusterIssuerName)
spec:
  ca:
    secretName: gokselfsign-ca
EOYAML
  kubectl --timeout=10s wait --for=condition=Ready clusterissuers.cert-manager.io $(getClusterIssuerName)

  # Add the self signed issuer(ca) certificate to authorized certificates
  kubectl get secrets -n cert-manager gokselfsign-ca -o json | jq -r '.data["tls.crt"]' | base64 -d > /usr/local/share/ca-certificates/issuer.crt
  update-ca-certificates
  #Need to restart the container
fi


  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: gokcloud-com-tls
  namespace: default
spec:
  secretName: gokcloud-com
  issuerRef:
    name: $(getClusterIssuerName)
    kind: ClusterIssuer
  commonName: kube.gokcloud.com
  dnsNames:
    - kube.gokcloud.com
  issuerRef:
    name: $(getClusterIssuerName)
    kind: ClusterIssuer
EOF

echoWarning "Selfsigned certificate is added to root ca, please reboot the system for it to effect"
}

certManagerReset() {
  kubectl delete Issuers,ClusterIssuers,Certificates,CertificateRequests,Orders,Challenges --all --all-namespaces
  helm --namespace cert-manager delete cert-manager
  kubectl delete namespace cert-manager
  kubectl delete -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.2/cert-manager.crds.yaml

  if [[ $CERTMANAGER_CHALANGE_TYPE == 'dns' ]]; then godaddyWebhook; fi
}

#Godday api calls are disabled, hence going to remove this call.
godaddyWebhook() {
  kubectl apply -f https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/godaddy-cert-webhook/webhook-all.yml --validate=false
  echo "Provide godaddy apikey and secret <API_KEY:SECRET>"
  # shellcheck disable=SC2162
  read API_KEY

  cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: godaddy-api-key-secret
  namespace: cert-manager
type: Opaque
stringData:
  api-key: ${API_KEY}
EOF

  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    email: majisumitkumar@gmail.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - dns01:
        webhook:
          config:
            apiKeySecretRef:
              name: godaddy-api-key-secret
              key: api-key
            production: true
            ttl: 600
          groupName: gokcloud.com
          solverName: godaddy
      selector:
       dnsNames:
       - 'kube.gokcloud.com'
       - '*.gokcloud.com'
EOF

  cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: gokcloud-com-tls
  namespace: default
spec:
  secretName: gokcloud-com
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: kube.gokcloud.com
  dnsNames:
    - kube.gokcloud.com
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
EOF

}

godaddyWebhookReset() {
  kubectl delete -f https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/godaddy-cert-webhook/webhook-all.yml
  kubectl delete secret godaddy-api-key-secret -n cert-manager
}

haInst() {
  docker stop master-proxy
  docker rm master-proxy
  cat <<EOF >/opt/haproxy.cfg
global
        log 127.0.0.1 local0
        log 127.0.0.1 local1 notice
        maxconn 4096
        maxpipes 1024
        daemon
defaults
        log global
        mode tcp
        option tcplog
        option dontlognull
        option redispatch
        option http-server-close
        retries 3
        timeout connect 5000
        timeout client 50000
        timeout server 50000
        frontend default_frontend
        bind *:$HA_PROXY_PORT
        default_backend master-cluster
backend master-cluster
$(#Install master nodes
    IFS=','
    counter=0
    cluster=""
    for worker in $API_SERVERS; do
      oifs=$IFS
      IFS=':'
      read -r ip node <<<"$worker"
      if [ -z "$cluster" ]; then
        cluster="$ip:6443"
      else
        cluster="$cluster,http://$ip:4001"
      fi
      counter=$((counter + 1))
      IFS=$oifs
      echo "        server master-$counter ${cluster} check"
      cluster=""
    done
    unset IFS
  )
EOF

  docker run -d --name master-proxy \
    -v /opt/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro \
    --net=host haproxy
}

startKubelet() {
  systemctl stop kubelet
  systemctl start kubelet
}

startHa() {
  docker stop master-proxy
  docker rm master-proxy
  docker run -d --name master-proxy \
    -v /opt/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro \
    --net=host haproxy
}

disableSwap() {
  sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
  sudo swapoff -a
}

hostSecret() {
  openssl genrsa -out ${APP_HOST}.key 4096
  openssl req -new -key ${APP_HOST}.key -out ${APP_HOST}.csr -subj "/CN=${APP_HOST}" \
    -addext "subjectAltName = DNS:${APP_HOST}"
  openssl x509 -req -in ${APP_HOST}.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out ${APP_HOST}.crt -days 7200

  kubectl create secret tls appingress-certificate --key ${APP_HOST}.key --cert ${APP_HOST}.crt -n default
}

dashboardInst() {
  helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
  kubectl delete ns kubernetes-dashboard
  helm install kubernetes-dashboard \
    kubernetes-dashboard/kubernetes-dashboard \
    --namespace kubernetes-dashboard \
    --create-namespace \
    -f https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/dashboard/values2.yaml
}

prometheusGrafanaReset() {
  helm -n monitoring delete monitoring
  kubectl delete ns monitoring
  helm -n db delete postgres
  kubectl delete ns db
}

emptyLocalFsStorageKeycloak(){
  kubectl delete pv keycloak-pv
  kubectl delete sc keycloak-storage
  rm -rf /data/volumes/pv3
}

emptyLocalFsStorageRegistry(){
  kubectl delete pvc --all -n regisry
  kubectl delete pv registry-pv
  kubectl delete sc registry-storage
  rm -rf /data/volumes/pv4
}

emptyLocalFsStorageMonotring(){
  kubectl delete pv prometheus-pv
  kubectl delete pv alertmanager-pv
  kubectl delete sc prometheus-storage
  kubectl delete sc alertmanager-storage
  rm -rf /data/volumes/{pv1,pv2}
}

localFsStorageClassKeycloakCreate(){
  cat << EOF | kubectl apply -f -
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: keycloak-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF

  mkdir -p /data/volumes/pv3
  chmod 777 /data/volumes/pv3

  cat << EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolume
metadata:
  name: keycloak-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: keycloak-storage
  local:
    path: /data/volumes/pv3
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - master.cloud.com
EOF
}

localFsStorageClassMonitoringCreate(){
  cat << EOF | kubectl apply -f -
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: prometheus-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF

  cat << EOF | kubectl apply -f -
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: alertmanager-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF

  mkdir -p /data/volumes/pv1
  chmod 777 /data/volumes/pv1
  mkdir -p /data/volumes/pv2
  chmod 777 /data/volumes/pv2

  cat << EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolume
metadata:
  name: prometheus-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: prometheus-storage
  local:
    path: /data/volumes/pv1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - master.cloud.com
EOF

  cat << EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolume
metadata:
  name: alertmanager-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: alertmanager-storage
  local:
    path: /data/volumes/pv2
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - master.cloud.com
EOF

}

localFsStorageClassRegistryCreate(){
  cat << EOF | kubectl apply -f -
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: registry-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF

  mkdir -p /data/volumes/pv4
  chmod 777 /data/volumes/pv4

  cat << EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolume
metadata:
  name: registry-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: registry-storage
  local:
    path: /data/volumes/pv4
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - master.cloud.com
EOF

}

prometheusGrafanaResetv2(){
  helm -n monitoring delete prometheus
  helm -n monitoring delete grafana
  kubectl delete ns monitoring

}

prometheusGrafanaInstv2(){
  helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  helm repo add grafana https://grafana.github.io/helm-charts
  helm repo update
  helm install prometheus prometheus-community/prometheus \
    --values https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/prometheus-grafana/prometheus-values.yaml \
    --namespace monitoring \
    --create-namespace

  helm install grafana grafana/grafana \
    --values https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/prometheus-grafana/grafana-values.yaml \
    --namespace monitoring

  kubectl -n kube-system get cm kube-proxy -o yaml | sed 's/metricsBindAddress: ""/metricsBindAddress: 0.0.0.0:10249/' | kubectl apply -f -

  kubectl -n kube-system patch ds kube-proxy -p \
      '{"spec":{"template":{"metadata":{"labels":{"updateTime":"'`date +'%s'`'"}}}}}'


}

prometheusGrafanaInst() {

  helm repo add prometheus-community \
    https://prometheus-community.github.io/helm-charts
  helm repo update
  helm install monitoring \
    prometheus-community/kube-prometheus-stack \
    --values https://github.com/sumitmaji/kubernetes/raw/master/install_k8s/prometheus-grafana/values.yaml \
    --version 39.6.0 \
    --namespace monitoring \
    --create-namespace

#  kubectl -n kube-system get cm kube-proxy-config -o yaml | sed \
#    's/metricsBindAddress: 127.0.0.1:10249/metricsBindAddress: 0.0.0.0:10249' \
#    kubectl apply -f -

  kubectl -n kube-system get cm kube-proxy -o yaml | sed 's/metricsBindAddress: ""/metricsBindAddress: 0.0.0.0:10249/' | kubectl apply -f -

  kubectl -n kube-system patch ds kube-proxy -p \
    '{"spec":{"template":{"metadata":{"labels":{"updateTime":"'`date +'%s'`'"}}}}}'

  helm repo add bitnami https://charts.bitnami.com/bitnami
  helm repo update
  helm install postgres \
    bitnami/postgresql \
    --values https://github.com/sumitmaji/kubernetes/raw/master/install_k8s/prometheus-grafana/postgres-values.yaml \
    --version 11.7.1 \
    --namespace db \
    --create-namespace

}

dashboardReset() {
  helm uninstall kubernetes-dashboard -n kubernetes-dashboard
  helm delete ns kubernetes-dashboard
}

adminRole() {
  WC=$(kubectl get clusterrolebinding cloud-cluster-admin 2>/dev/null | wc -l)
  if [ "$WC" == "0" ]; then

    cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cloud-cluster-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: cloud:masters
EOF
  fi

}

resetDockerRegistry(){
  helm uninstall registry -n registry
  emptyLocalFsStorageRegistry
  kubectl delete ns registry
}

# https://itnext.io/error-x509-certificate-signed-by-unknown-authority-error-is-returned-f0e5d436f467
# Generate User & Password
genRegistyrPassword(){
  export REGISTRY_USER=sumit
  export REGISTRY_PASS=sumit
  export DESTINATION_FOLDER=./registry-creds

  # Backup credentials to local files (in case you'll forget them later on)
  mkdir -p ${DESTINATION_FOLDER}
  echo ${REGISTRY_USER} > ${DESTINATION_FOLDER}/registry-user.txt
  echo ${REGISTRY_PASS} > ${DESTINATION_FOLDER}/registry-pass.txt

  docker run --entrypoint htpasswd registry:2.7.0 \
      -Bbn ${REGISTRY_USER} ${REGISTRY_PASS} \
      > ${DESTINATION_FOLDER}/htpasswd

  unset REGISTRY_USER REGISTRY_PASS DESTINATION_FOLDER
}

# https://blog.zachinachshon.com/docker-registry/
# Verify access to the registry
verifyRegistyrInst(){
  export DESTINATION_FOLDER=./registry-creds
  export USER=$(cat ${DESTINATION_FOLDER}/registry-user.txt)
  export PASSWORD=$(cat ${DESTINATION_FOLDER}/registry-pass.txt)

  curl -kiv -H \
    "Authorization: Basic $(echo -n "${USER}:${PASSWORD}" | base64)" \
    https://registry.gokcloud.com/v2/_catalog

  wget --no-check-certificate --header \
    "Authorization: Basic $(echo -n "${USER}:${PASSWORD}" | base64)" \
    https://registry.gokcloud.com/v2/_catalog

  unset USER PASSWORD
}

# https://itnext.io/error-x509-certificate-signed-by-unknown-authority-error-is-returned-f0e5d436f467
dockerRegistryInst(){
  genRegistyrPassword
  helm repo add twuni https://helm.twun.io
  export DESTINATION_FOLDER=./registry-creds
  helm upgrade --install registry \
      --namespace registry \
      --create-namespace \
      --set replicaCount=1 \
      --set persistence.enabled=true \
      --set persistence.size=10Gi \
      --set persistence.deleteEnabled=true \
      --set persistence.storageClass=registry-storage \
      --set secrets.htpasswd=$(cat ${DESTINATION_FOLDER}/htpasswd) \
      --values https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/registry/values.yaml \
      twuni/docker-registry

}

# It is used to generate both client/server certificate using
# Kubernetes ca certificate in /etc/kubernetes/pki/ca.crt
createCertificate(){
  [[ "TRACE" ]] && set -x

  : ${INSTALL_PATH:=$MOUNT_PATH/kubernetes/install_k8s}

  while [[ $# -gt 0 ]]
  do
  key="$1"
  case $key in
   -i|--ip)
   NODE_IP="$2"
   shift
   shift
   ;;
   -h|--host)
   HOSTNAME="$2"
   shift
   shift
   ;;
   -f|--file)
   FILENAME="$2"
   shift
   shift
   ;;
   -t|--type)
   TYPE="$2"
   shift
   shift
   ;;
  esac
  done

  if [ -z "$NODE_IP" ]
  then
  	echo "Please provide node ip"
  	exit 0
  fi
  if [ -z "$HOSTNAME" ]
  then
          echo "Please provide node hostname"
          exit 0
  fi
  if [ -z "$FILENAME" ]
  then
          echo "Please provide node filename"
          exit 0
  fi
  if [ -z "$TYPE" ]
  then
          echo "Please provide file type"
          exit 0
  fi

  : ${COUNTRY:=IN}
  : ${STATE:=UP}
  : ${LOCALITY:=GN}
  : ${ORGANIZATION:=CloudInc}
  : ${ORGU:=IT}
  : ${EMAIL:=cloudinc.gmail.com}
  : ${COMMONNAME:=kube-system}

  mkdir -p $MOUNT_PATH/certs
  pushd $MOUNT_PATH/certs

  if [ $TYPE == 'server' ]
  then
   keyUsage='extendedKeyUsage = clientAuth,serverAuth'
   #HOSTNAME="${HOSTNAME}-${FILENAME}" # Need to see why I did that
  else
   keyUsage='extendedKeyUsage = clientAuth'
   FILENAME="${FILENAME}-client"
   #HOSTNAME="${HOSTNAME}-$FILENAME"
  fi

  cat <<EOF | sudo tee ${FILENAME}-openssl.cnf
[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
$keyUsage
`
if [ $TYPE == 'server' ]
then
echo "subjectAltName = IP:$NODE_IP, DNS:$HOSTNAME"
fi`
EOF

  #Create a private key
  openssl genrsa -out $HOSTNAME.key 2048

  #Create CSR for the node
  openssl req -new -key $HOSTNAME.key \
    -subj "/CN=$NODE_IP" \
    -subj "/C=$COUNTRY/ST=$STATE/L=$LOCALITY/O=$ORGANIZATION/OU=$ORGU/CN=$HOSTNAME/emailAddress=$EMAIL" \
    -out $HOSTNAME.csr -config ${FILENAME}-openssl.cnf

  #Create a self signed certificate
  openssl x509 -req -in $HOSTNAME.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial \
    -out $HOSTNAME.crt -days 10000 -extensions v3_req -extfile ${FILENAME}-openssl.cnf

  #Copy ca.crt to crt
  cat /etc/kubernetes/pki/ca.crt >> $HOSTNAME.crt

  #Verify a Private Key Matches a Certificate
  openssl x509 -noout -text -in $HOSTNAME.crt

  popd
}

# It is used to generate client certificate
# using kubectl command
createClientCertificate(){
  USERNAME=$1
  GROUPNAME=$2
  echo + Creating private key: ${USERNAME}.key
  openssl genrsa -out ${USERNAME}.key 4096

  echo + Creating signing request: ${USERNAME}-csr
  openssl req -new -key ${USERNAME}.key -out ${USERNAME}.csr -subj "/CN=${USERNAME}/O=${GROUPNAME}" \
          -addext "subjectAltName = DNS:${USERNAME}"

  WC=$(kubectl get csr ${USERNAME}-csr 2>/dev/null | wc -l)
  if [ "$WC" != "0" ]; then
    kubectl delete csr ${USERNAME}-csr
  fi
  echo + Creating signing request in kubernetes
  cat <<EOF | kubectl create -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: ${USERNAME}-csr
spec:
  groups:
    - system:authenticated
    - ${GROUPNAME}
  request: $(cat ${USERNAME}.csr | base64 | tr -d '\n')
  signerName: kubernetes.io/kube-apiserver-client
  usages:
    - digital signature
    - key encipherment
    - client auth
EOF

  kubectl certificate approve ${USERNAME}-csr

  kubectl get csr ${USERNAME}-csr -o jsonpath='{.status.certificate}' | base64 -d >${USERNAME}.crt
}

# The method creates certificate for user having admin role and generate kube config file
# for login to api server
createKubeConfig() {
  USERNAME=$1
  : ${IP:=$(ifconfig eth0 2>/dev/null | awk '/inet / {print $2}' | sed 's/addr://')}
  if [ -z "$IP" ]; then
    : ${IP:=$(ifconfig enp0s3 2>/dev/null | awk '/inet / {print $2}' | sed 's/addr://')}
  fi
  adminRole
  echo + Creating private key: ${USERNAME}.key
  openssl genrsa -out ${USERNAME}.key 4096

  echo + Creating signing request: ${USERNAME}.csr
  openssl req -new -key ${USERNAME}.key -out ${USERNAME}.csr -subj "/CN=${USERNAME}/O=cloud:masters"
  WC=$(kubectl get csr ${USERNAME}-csr 2>/dev/null | wc -l)
  if [ "$WC" != "0" ]; then
    kubectl delete csr ${USERNAME}-csr
  fi
  echo + Creating signing request in kubernetes
  cat <<EOF | kubectl create -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: ${USERNAME}-csr
spec:
  groups:
    - system:authenticated
    - cloud:masters
  request: $(cat ${USERNAME}.csr | base64 | tr -d '\n')
  signerName: kubernetes.io/kube-apiserver-client
  usages:
    - digital signature
    - key encipherment
    - client auth
EOF

  kubectl certificate approve ${USERNAME}-csr

  kubectl get csr ${USERNAME}-csr -o jsonpath='{.status.certificate}' | base64 -d >${USERNAME}.crt

  echo "======Kubeconfig file user ${USERNAME}.conf generated"

  kubectl config set-cluster cloud.com --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --server=https://${IP}:6443 --kubeconfig=/root/${USERNAME}.conf
  kubectl config set-credentials ${USERNAME} --client-key=${USERNAME}.key --client-certificate=${USERNAME}.crt --embed-certs=true --kubeconfig=/root/${USERNAME}.conf
  kubectl config --kubeconfig=/root/${USERNAME}.conf set-context ${USERNAME}@cloud.com --cluster=cloud.com --user=${USERNAME}
  kubectl config --kubeconfig=/root/${USERNAME}.conf use-context ${USERNAME}@cloud.com

  rm ${USERNAME}.key ${USERNAME}.csr ${USERNAME}.crt

}

patchLdapSecure() {
  kubectl patch ing "$NAME" --patch "$(
    cat <<EOF
metadata:
  annotations:
    nginx.ingress.kubernetes.io/auth-signin: https://kube.gokcloud.com/authenticate
    nginx.ingress.kubernetes.io/auth-url: https://kube.gokcloud.com/check
EOF
  )" -n "$NS"
}

patchLetsEncrypt() {
  NAME=$1
  NS=$2
  SUBDOMAIN=$(subDomain $3)

  kubectl patch ing "$NAME" --patch "$(
    cat <<EOF
metadata:
  annotations:
    #certmanager.k8s.io/cluster-issuer: $(getClusterIssuerName)
    cert-manager.io/cluster-issuer: $(getClusterIssuerName)
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
    - hosts:
        - ${SUBDOMAIN}.gokcloud.com
      secretName: ${SUBDOMAIN}-gokcloud-com
EOF
  )" -n "$NS"
  kubectl patch ing "$NAME" --type=json -p='[{"op": "replace", "path": "/spec/rules/0/host", "value":"'$SUBDOMAIN'.gokcloud.com"}]' -n "$NS"

  kubectl --timeout=10s -n ${NS} wait --for=condition=Ready certificates.cert-manager.io ${SUBDOMAIN}-gokcloud-com
}

kcd(){
  alias kcd='kubectl config set-context $(kubectl config current-context) --namespace'
}

helmTemplateDebug(){
  CHART_NAME=$1
  CHART_REPO=$2
  helm install $1 $2  \
    --dry-run --debug | less
}

keycloakReset(){
  helm uninstall keycloak -n keycloak
  kubectl delete pvc --all -n keycloak
  emptyLocalFsStorageKeycloak
  kubectl delete ns keycloak
}

k(){
  alias k='kubectl'
}

keycloakInst(){

  helm install keycloak oci://registry-1.docker.io/bitnamicharts/keycloak \
        --namespace keycloak \
        --create-namespace \
        -f https://github.com/sumitmaji/kubernetes/raw/q1/install_k8s/keycloak/values2.yaml
}

installRegistryWithCertMgr(){
  localFsStorageClassRegistryCreate
  dockerRegistryInst
  # No need to generate the certificate.
  # The certificate and secret will be directory issued the ingress annotation cert-manager.io/cluster-issuer
  # ./gok create certificate registry registry
  ./gok patch ingress registry-docker-registry registry letsencrypt registry

  # Let docker trust the self-signed certificates
  # https://itnext.io/error-x509-certificate-signed-by-unknown-authority-error-is-returned-f0e5d436f467
  #BEGIN
  rm /etc/docker/certs.d/registry.gokcloud.com/ca.crt
  mkdir -p /etc/docker/certs.d/registry.gokcloud.com/
  kubectl get secret registry-gokcloud-com -o jsonpath="{['data']['tls\.crt']}" | base64 --decode > /etc/docker/certs.d/registry.gokcloud.com/ca.crt
  systemctl restart docker
  #END

  # Restarting docker stops the haproxy, need to start it again
  ./gok start proxy
  docker login registry.gokcloud.com
  [[ $? -eq 0 ]] && echoSuccess "OK" || echoFailed "FAILED"
  openssl s_client -connect registry.gokcloud.com:443 -showcerts </dev/null | grep 'Verify return code: 0 (ok)'
  [[ $? -eq 0 ]] && echoSuccess "Registry certificate verification succeeded" || echoFailed "Registry certificate verification failed"
}

installKeycloakWithCertMgr(){
  keycloakInst
  localFsStorageClassKeycloakCreate
  # No need to generate the certificate.
  # The certificate and secret will be directory issued the ingress annotation cert-manager.io/cluster-issuer
  #./gok create certificate keycloak keycloak
  ./gok patch ingress keycloak keycloak letsencrypt keycloak

  echo "Waiting for services to be up!!!!"
  kubectl --timeout=120s wait --for=condition=Ready pods --all --namespace keycloak
  [[ $? -eq 0 ]] && echoSuccess "Keycloak services are now up!\nAccess it using https://keycloak.gokcloud.com/" || echoFailed "Keycloak services timed-out, plaese check!!"
}

installPrometheusGrafanaWithCertMgr(){
  ./gok install monitoring
  ./gok create certificate monitoring kube
  ./gok patch ingress prometheus-server monitoring letsencrypt kube
  ./gok patch ingress grafana monitoring letsencrypt kube
}

installDashboardwithCertManager(){
  ./gok install dashboard
  ./gok create certificate kubernetes-dashboard kube
  ./gok patch ingress kubernetes-dashboard kubernetes-dashboard letsencrypt kube
}

decodeSecret(){
  SECRET=$1
  NS=$2
  kubectl get secret -n $NS $SECRET -o json | jq -r '.data."tls.crt"' | base64 -d | openssl x509 -noout -text
}

patchLocalTls() {
  NAME=$1
  NS=$2
  kubectl patch ing "$NAME" --patch "$(
    cat <<EOF
spec:
  tls:
    - hosts:
        - $APP_HOST
      secretName: appingress-certificate
EOF
  )" -n "$NS"
  kubectl patch ing "$NAME" --type=json -p='[{"op": "replace", "path": "/spec/rules/0/host", "value":"master.cloud.com"}]' -n "$NS"
  kubectl patch ing "$NAME" --type=json -p='[{"op": "add", "path": "/metadata/annotations", "value":{"nginx.ingress.kubernetes.io/rewrite-target": "/", "kubernetes.io/ingress.class": "nginx"}}]' -n "$NS"
}

if [ "$CMD" == "bash" ]; then
  pod=$(getpod)
  echo "Opening terminal on $pod"
  kubectl exec -it "$pod" -- /bin/bash
elif [ "$CMD" == "desc" ]; then
  pod=$(getpod)
  echo "Describing pod $pod"
  kubectl describe po "$pod"
elif [ "$CMD" == "logs" ]; then
  pod=$(getpod)
  echo "Viewing logs of pod $pod"
  kubectl logs "$pod"
elif [ "$CMD" == "status" ]; then
  helm status "$release"
elif [ "$CMD" == "taint-node" ]; then
  taintNode
elif [ "$CMD" == "install" ]; then
  updateSys
  installDeps
  COMPONENT=$2
  if [ "$COMPONENT" == "docker" ]; then
    dockrInst
  elif [ "$COMPONENT" == "cert-manager" ]; then
    certmanagerInst
    setupCertiIssuers
  elif [ "$COMPONENT" == "monitoring" ]; then
    #prometheusGrafanaInst
    localFsStorageClassMonitoringCreate
    prometheusGrafanaInstv2
  elif [ "$COMPONENT" == "dashboard" ]; then
    dashboardInst
  elif [ "$COMPONENT" == "keycloak" ]; then
    installKeycloakWithCertMgr
  elif [ "$COMPONENT" == "ingress" ]; then
    ingressInst
  elif [ "$COMPONENT" == "registry" ]; then
        installRegistryWithCertMgr
  elif [ "$COMPONENT" == "kubernetes" ]; then
    dockrInst
    haInst
    k8sInst
    helmInst
    taintNode
    calicoInst
    customDns
    cat <<EOF
\______   |  |   ____ _____    ______ ____   __  _  ______  |___/  |_  _/ _______________  /_   |   _____ |__| ____
 |     ___|  | _/ __ \\__  \  /  ____/ __ \  \ \/ \/ \__  \ |  \   __\ \   __/  _ \_  __ \  |   |  /     \|  |/    \
 |    |   |  |_\  ___/ / __ \_\___ \\  ___/   \     / / __ \|  ||  |    |  |(  <_> |  | \/  |   | |  Y Y  |  |   |  \
 |____|   |____/\___  (____  /____  >\___  >   \/\_/ (____  |__||__|    |__| \____/|__|     |___| |__|_|  |__|___|  / /\
                    \/     \/     \/     \/               \/                                            \/        \/  \/
EOF
  fi
elif [ "$CMD" == "start" ]; then
  COMPONENT=$2
  if [ "$COMPONENT" == "kubernetes" ]; then
    disableSwap
    startHa
    startKubelet
  elif [ "$COMPONENT" == "proxy" ]; then
    startHa
  elif [ "$COMPONET" == "kubelet" ]; then
    startKubelet
  fi
elif [ "$CMD" == "reset" ]; then
  COMPONENT=$2
  if [ "$COMPONENT" == "kubernetes" ]; then
    kubeadm reset <<EOF
y
EOF
  elif [ "$COMPONENT" == "monitoring" ]; then
    #prometheusGrafanaReset
    prometheusGrafanaResetv2
    emptyLocalFsStorageMonotring
  elif [ "$COMPONENT" == "dashboard" ]; then
    dashboardReset
  elif [ "$COMPONENT" == "keycloak" ]; then
    keycloakReset
  elif [ "$COMPONENT" == "ingress" ]; then
    ingressUnInst
  elif [ "$COMPONENT" == "registry" ]; then
    resetDockerRegistry
  elif [ "$COMPONENT" == "cert-manager" ]; then
    certManagerReset
  fi
elif [ "$CMD" == "deploy" ]; then
  COMPONENT=$2
  if [ "$COMPONENT" == "app1" ]; then
    createApp1
  fi
elif [ "$CMD" == "patch" ]; then
  RESOURCE=$2
  NAME=$3
  NS=$4
  OPTIONS=$5
  SUBDOMAIN=$6
  if [ "$RESOURCE" == "ingress" ]; then
    if [ "$OPTIONS" == "letsencrypt" ]; then
      patchLetsEncrypt "$NAME" "$NS" "$SUBDOMAIN"
    elif [ "$OPTIONS" == "ldap" ]; then
      patchLdapSecure "$NAME" "$NS"
    elif [ "$OPTIONS" == "localtls" ]; then
      patchLocalTls "$NAME" "$NS"
    fi
  fi
elif [ "$CMD" == "create" ]; then
  RESOURCE=$2
  NAME=$3
  ADDITIONAL=$4
  if [ "$RESOURCE" == "secret" ]; then
    if [ "$NAME" == "apphost" ]; then
      hostSecret
    fi
  elif [ "$RESOURCE" == "certificate" ]; then
    certificateRequestForNs "$NAME" "$ADDITIONAL"
  elif [ "$RESOURCE" == "kubeconfig" ]; then
    createKubeConfig "$NAME"
  fi
fi
